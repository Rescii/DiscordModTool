txt");
var secondOut = fs.createWriteStream("second.txt");
firstPart.pipe(firstOut);
secondPart.pipe(secondOut);
```

## API Documentation

### fdSlicer.createFromFd(fd, [options])

```js
var fdSlicer = require('fd-slicer');
fs.open("file.txt", 'r', function(err, fd) {
  if (err) throw err;
  var slicer = fdSlicer.createFromFd(fd);
  // ...
});
```

Make sure `fd` is a properly initialized file descriptor. If you want to
use `createReadStream` make sure you open it for reading and if you want
to use `createWriteStream` make sure you open it for writing.

`options` is an optional object which can contain:

 * `autoClose` - if set to `true`, the file descriptor will be automatically
   closed once the last stream that references it is closed. Defaults to
   `false`. `ref()` and `unref()` can be used to increase or decrease the
   reference count, respectively.

### fdSlicer.createFromBuffer(buffer, [options])

```js
var fdSlicer = require('fd-slicer');
var slicer = fdSlicer.createFromBuffer(someBuffer);
// ...
```

`options` is an optional object which can contain:

 * `maxChunkSize` - A `Number` of bytes. see `createReadStream()`.
   If falsey, defaults to unlimited.

#### Properties

##### fd

The file descriptor passed in. `undefined` if created from a buffer.

#### Methods

##### createReadStream(options)

Available `options`:

 * `start` - Number. The offset into the file to start reading from. Defaults
   to 0.
 * `end` - Number. Exclusive upper bound offset into the file to stop reading
   from.
 * `highWaterMark` - Number. The maximum number of bytes to store in the
   internal buffer before ceasing to read from the underlying resource.
   Defaults to 16 KB.
 * `encoding` - String. If specified, then buffers will be decoded to strings
   using the specified encoding. Defaults to `null`.

The ReadableStream that this returns has these additional methods:

 * `destroy(err)` - stop streaming. `err` is optional and is the error that
   will be emitted in order to cause the streaming to stop. Defaults to
   `new Error("stream destroyed")`.

If `maxChunkSize` was specified (see `createFromBuffer()`), the read stream
will provide chunks of at most that size. Normally, the read stream provides
the entire range requested in a single chunk, but this can cause performance
problems in some circumstances.
See [thejoshwolfe/yauzl#87](https://github.com/thejoshwolfe/yauzl/issues/87).

##### createWriteStream(options)

Available `options`:

 * `start` - Number. The offset into the file to start writing to. Defaults to
   0.
 * `end` - Number. Exclusive upper bound offset into the file. If this offset
   is reached, the write stream will emit an 'error' event and stop functioning.
   In this situation, `err.code === 'ETOOBIG'`. Defaults to `Infinity`.
 * `highWaterMark` - Number. Buffer level when `write()` starts returning
   false. Defaults to 16KB.
 * `decodeStrings` - Boolean. Whether or not to decode strings into Buffers
   before passing them to` _write()`. Defaults to `true`.

The WritableStream that this returns has these additional methods:

 * `destroy()` - stop streaming

And these additional properties:

 * `bytesWritten` - number of bytes written to the stream

And these additional events:

 * 'progress' - emitted when `bytesWritten` changes.

##### read(buffer, offset, length, position, callback)

Equivalent to `fs.read`, but with concurrency protection.
`callback` must be defined.

##### write(buffer, offset, length, position, callback)

Equivalent to `fs.write`, but with concurrency protection.
`callback` must be defined.

##### ref()

Increase the `autoClose` reference count by 1.

##### unref()

Decrease the `autoClose` reference count by 1.

#### Events

##### 'error'

Emitted if `fs.close` returns an error when auto closing.

##### 'close'

Emitted when fd-slicer closes the file descriptor due to `autoClose`. Never
emitted if created from a buffer.
var fdSlicer = require('../');
var fs = require('fs');
var crypto = require('crypto');
var path = require('path');
var streamEqual = require('stream-equal');
var assert = require('assert');
var Pend = require('pend');
var StreamSink = require('streamsink');

var describe = global.describe;
var it = global.it;
var before = global.before;
var beforeEach = global.beforeEach;
var after = global.after;

var testBlobFile = path.join(__dirname, "test-blob.bin");
var testBlobFileSize = 20 * 1024 * 1024;
var testOutBlobFile = path.join(__dirname, "test-blob-out.bin");

describe("FdSlicer", function() {
  before(function(done) {
    var out = fs.createWriteStream(testBlobFile);
    for (var i = 0; i < testBlobFileSize / 1024; i += 1) {
      out.write(crypto.pseudoRandomBytes(1024));
    }
    out.end();
    out.on('close', done);
  });
  beforeEach(function() {
    try {
      fs.unlinkSync(testOutBlobFile);
    } catch (err) {
    }
  });
  after(function() {
    try {
      fs.unlinkSync(testBlobFile);
      fs.unlinkSync(testOutBlobFile);
    } catch (err) {
    }
  });
  it("reads a 20MB file (autoClose on)", function(done) {
    fs.open(testBlobFile, 'r', function(err, fd) {
      if (err) return done(err);
      var slicer = fdSlicer.createFromFd(fd, {autoClose: true});
      var actualStream = slicer.createReadStream();
      var expectedStream = fs.createReadStream(testBlobFile);

      var pend = new Pend();
      pend.go(function(cb) {
        slicer.on('close', cb);
      });
      pend.go(function(cb) {
        streamEqual(expectedStream, actualStream, function(err, equal) {
          if (err) return done(err);
          assert.ok(equal);
          cb();
        });
      });
      pend.wait(done);
    });
  });
  it("reads 4 chunks simultaneously", function(done) {
    fs.open(testBlobFile, 'r', function(err, fd) {
      if (err) return done(err);
      var slicer = fdSlicer.createFromFd(fd);
      var actualPart1 = slicer.createReadStream({start: testBlobFileSize * 0/4, end: testBlobFileSize * 1/4});
      var actualPart2 = s